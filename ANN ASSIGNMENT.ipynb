{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## import libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_consanant = pd.read_csv('Data/Consonant.csv')\n",
    "train_vowel = pd.read_csv('Data/Vowel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1155/1155 [00:12<00:00, 93.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 275/275 [00:02<00:00, 100.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_img = []\n",
    "for img_path in tqdm(train_consanant['FileName'].values):\n",
    "    train_img.append(read_img(TRAIN_PATH +\"Consonant/\"+ img_path))\n",
    "for img_path in tqdm(train_vowel['FileName'].values):\n",
    "    train_img.append(read_img(TRAIN_PATH +\"Vowel/\"+ img_path))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(train_img, np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [0]*1430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1155,1430):\n",
    "    y_train[x] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D,Conv2D,BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 224,224\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "nb_train_samples = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath =\"weights.{epoch:02d}-{val_acc:.2f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelCheckpnt =ModelCheckpoint(filepath=filepath,monitor='val_acc',verbose=1,save_best_only=True,save_weights_only=False,period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tboard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=64, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1072 samples, validate on 358 samples\n",
      "Epoch 1/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 3.0108 - acc: 0.6387Epoch 00000: val_acc improved from -inf to 0.81285, saving model to weights.00-0.81.hdf5\n",
      "1072/1072 [==============================] - 6s - loss: 2.9434 - acc: 0.6446 - val_loss: 1.0587 - val_acc: 0.8128\n",
      "Epoch 2/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.8212 - acc: 0.7373Epoch 00001: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.8074 - acc: 0.7435 - val_loss: 1.3051 - val_acc: 0.3520\n",
      "Epoch 3/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.4780 - acc: 0.7920Epoch 00002: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.4750 - acc: 0.7957 - val_loss: 1.2990 - val_acc: 0.2011\n",
      "Epoch 4/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.4327 - acc: 0.8223Epoch 00003: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.4237 - acc: 0.8228 - val_loss: 0.7983 - val_acc: 0.2235\n",
      "Epoch 5/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.3629 - acc: 0.8584Epoch 00004: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.3695 - acc: 0.8582 - val_loss: 1.2816 - val_acc: 0.1872\n",
      "Epoch 6/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.3283 - acc: 0.8682Epoch 00005: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.3233 - acc: 0.8713 - val_loss: 2.0320 - val_acc: 0.1872\n",
      "Epoch 7/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2652 - acc: 0.8857Epoch 00006: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2688 - acc: 0.8834 - val_loss: 0.8650 - val_acc: 0.3128\n",
      "Epoch 8/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2950 - acc: 0.8955Epoch 00007: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2923 - acc: 0.8965 - val_loss: 2.1266 - val_acc: 0.1872\n",
      "Epoch 9/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2608 - acc: 0.8916Epoch 00008: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2606 - acc: 0.8918 - val_loss: 0.5277 - val_acc: 0.7877\n",
      "Epoch 10/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2277 - acc: 0.9160Epoch 00009: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2189 - acc: 0.9198 - val_loss: 0.5941 - val_acc: 0.6899\n",
      "Epoch 11/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2170 - acc: 0.9160Epoch 00010: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2304 - acc: 0.9132 - val_loss: 1.5566 - val_acc: 0.2123\n",
      "Epoch 12/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.2425 - acc: 0.9150Epoch 00011: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2389 - acc: 0.9160 - val_loss: 0.5710 - val_acc: 0.7039\n",
      "Epoch 13/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1555 - acc: 0.9482Epoch 00012: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1525 - acc: 0.9478 - val_loss: 1.9889 - val_acc: 0.2039\n",
      "Epoch 14/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1112 - acc: 0.9570Epoch 00013: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1124 - acc: 0.9571 - val_loss: 1.8178 - val_acc: 0.3240\n",
      "Epoch 15/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0909 - acc: 0.9609Epoch 00014: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1023 - acc: 0.9580 - val_loss: 0.7396 - val_acc: 0.5922\n",
      "Epoch 16/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1059 - acc: 0.9600Epoch 00015: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1061 - acc: 0.9608 - val_loss: 0.4737 - val_acc: 0.7654\n",
      "Epoch 17/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1069 - acc: 0.9658Epoch 00016: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1080 - acc: 0.9646 - val_loss: 1.5223 - val_acc: 0.4106\n",
      "Epoch 18/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.3191 - acc: 0.8975Epoch 00017: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.3194 - acc: 0.8983 - val_loss: 3.2787 - val_acc: 0.2095\n",
      "Epoch 19/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.3015 - acc: 0.9131Epoch 00018: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.2940 - acc: 0.9142 - val_loss: 0.5397 - val_acc: 0.7821\n",
      "Epoch 20/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1487 - acc: 0.9609Epoch 00019: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1534 - acc: 0.9580 - val_loss: 1.2078 - val_acc: 0.6034\n",
      "Epoch 21/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1704 - acc: 0.9424Epoch 00020: val_acc improved from 0.81285 to 0.88827, saving model to weights.20-0.89.hdf5\n",
      "1072/1072 [==============================] - 4s - loss: 0.1690 - acc: 0.9412 - val_loss: 0.3076 - val_acc: 0.8883\n",
      "Epoch 22/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0932 - acc: 0.9648Epoch 00021: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0901 - acc: 0.9655 - val_loss: 0.3885 - val_acc: 0.8827\n",
      "Epoch 23/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0733 - acc: 0.9756Epoch 00022: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0700 - acc: 0.9767 - val_loss: 0.3926 - val_acc: 0.8771\n",
      "Epoch 24/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0303 - acc: 0.9873Epoch 00023: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0291 - acc: 0.9879 - val_loss: 0.5992 - val_acc: 0.8017\n",
      "Epoch 25/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9824Epoch 00024: val_acc improved from 0.88827 to 0.94693, saving model to weights.24-0.95.hdf5\n",
      "1072/1072 [==============================] - 4s - loss: 0.0394 - acc: 0.9832 - val_loss: 0.2986 - val_acc: 0.9469\n",
      "Epoch 26/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0238 - acc: 0.9902Epoch 00025: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0227 - acc: 0.9907 - val_loss: 0.3156 - val_acc: 0.9162\n",
      "Epoch 27/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0204 - acc: 0.9932Epoch 00026: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0201 - acc: 0.9935 - val_loss: 0.3156 - val_acc: 0.9441\n",
      "Epoch 28/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0930 - acc: 0.9746Epoch 00027: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0902 - acc: 0.9748 - val_loss: 1.0396 - val_acc: 0.8855\n",
      "Epoch 29/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1081 - acc: 0.9648Epoch 00028: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1037 - acc: 0.9664 - val_loss: 0.3653 - val_acc: 0.9050\n",
      "Epoch 30/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1258 - acc: 0.9580Epoch 00029: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1506 - acc: 0.9534 - val_loss: 0.3784 - val_acc: 0.9358\n",
      "Epoch 31/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.1079 - acc: 0.9668Epoch 00030: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.1049 - acc: 0.9674 - val_loss: 2.5077 - val_acc: 0.5196\n",
      "Epoch 32/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0869 - acc: 0.9795Epoch 00031: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0842 - acc: 0.9804 - val_loss: 1.4988 - val_acc: 0.6927\n",
      "Epoch 33/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0486 - acc: 0.9844Epoch 00032: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0473 - acc: 0.9851 - val_loss: 0.8456 - val_acc: 0.8045\n",
      "Epoch 34/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0283 - acc: 0.9893Epoch 00033: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0290 - acc: 0.9888 - val_loss: 0.4363 - val_acc: 0.8966\n",
      "Epoch 35/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0817 - acc: 0.9756Epoch 00034: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0818 - acc: 0.9757 - val_loss: 0.4492 - val_acc: 0.9050\n",
      "Epoch 36/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0803 - acc: 0.9766Epoch 00035: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0782 - acc: 0.9767 - val_loss: 0.3240 - val_acc: 0.9413\n",
      "Epoch 37/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0279 - acc: 0.9902Epoch 00036: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0279 - acc: 0.9897 - val_loss: 0.3397 - val_acc: 0.9385\n",
      "Epoch 38/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0231 - acc: 0.9912Epoch 00037: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0221 - acc: 0.9916 - val_loss: 0.5389 - val_acc: 0.9302\n",
      "Epoch 39/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0431 - acc: 0.9873Epoch 00038: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0477 - acc: 0.9841 - val_loss: 0.8278 - val_acc: 0.8520\n",
      "Epoch 40/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0732 - acc: 0.9805Epoch 00039: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0763 - acc: 0.9776 - val_loss: 0.4406 - val_acc: 0.9050\n",
      "Epoch 41/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0453 - acc: 0.9873Epoch 00040: val_acc improved from 0.94693 to 0.96089, saving model to weights.40-0.96.hdf5\n",
      "1072/1072 [==============================] - 4s - loss: 0.0434 - acc: 0.9879 - val_loss: 0.1992 - val_acc: 0.9609\n",
      "Epoch 42/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0385 - acc: 0.9844Epoch 00041: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0371 - acc: 0.9851 - val_loss: 0.3028 - val_acc: 0.9413\n",
      "Epoch 43/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0196 - acc: 0.9932Epoch 00042: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0188 - acc: 0.9935 - val_loss: 0.3828 - val_acc: 0.9413\n",
      "Epoch 44/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0147 - acc: 0.9961Epoch 00043: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0144 - acc: 0.9963 - val_loss: 0.4277 - val_acc: 0.9274\n",
      "Epoch 45/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0115 - acc: 0.9941Epoch 00044: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0142 - acc: 0.9935 - val_loss: 0.3548 - val_acc: 0.9441\n",
      "Epoch 46/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0204 - acc: 0.9932Epoch 00045: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0212 - acc: 0.9925 - val_loss: 0.5896 - val_acc: 0.9246\n",
      "Epoch 47/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0203 - acc: 0.9912Epoch 00046: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0196 - acc: 0.9916 - val_loss: 0.6804 - val_acc: 0.9134\n",
      "Epoch 48/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0306 - acc: 0.9912Epoch 00047: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0293 - acc: 0.9916 - val_loss: 0.5438 - val_acc: 0.9358\n",
      "Epoch 49/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0082 - acc: 0.9951Epoch 00048: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0081 - acc: 0.9953 - val_loss: 0.3677 - val_acc: 0.9469\n",
      "Epoch 50/50\n",
      "1024/1072 [===========================>..] - ETA: 0s - loss: 0.0207 - acc: 0.9922Epoch 00049: val_acc did not improve\n",
      "1072/1072 [==============================] - 2s - loss: 0.0198 - acc: 0.9925 - val_loss: 0.3971 - val_acc: 0.9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216c94d3e80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=64,epochs=50,verbose=1,validation_data=(X_test,y_test),callbacks=[modelCheckpnt,Tboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = to_categorical(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAMALRAJ\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94326446055\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Consonant       0.99      0.94      0.96       291\n",
      "      Vowel       0.79      0.94      0.86        67\n",
      "\n",
      "avg / total       0.95      0.94      0.94       358\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,target_names=['Consonant','Vowel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
